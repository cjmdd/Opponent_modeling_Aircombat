{
  "algo": "APPO",
  "env": "dogfight_multi",
  "experiment": "dogfight4v4_v10",
  "experiments_root": null,
  "experiment_name": null,
  "help": false,
  "train_dir": "/home/cjm/study/game/test/course_learning/new/missile/missile_infer/missile_noshootpenalty/Intention_world/Intention_world_angle10_heightgain2_change_deltavratio1_vno0.1_remove_predist3_orientheight5000_nomanveur_angle_height_60_15_model2_combine_rawmissile_noobstacle_60s_hyperadd/train_dir",
  "device": "gpu",
  "seed": 1,
  "save_every_sec": 120,
  "keep_checkpoints": 3,
  "save_milestones_sec": -1,
  "stats_avg": 100,
  "learning_rate": 0.0001,
  "train_for_env_steps": 160000000,
  "train_for_seconds": 10000000000,
  "obs_subtract_mean": 0.0,
  "obs_scale": 1.0,
  "gamma": 0.99,
  "reward_scale": 1.0,
  "reward_clip": 10.0,
  "encoder_type": "mlp",
  "encoder_subtype": "mlp_quads",
  "encoder_custom": "quad_multi_encoder",
  "encoder_extra_fc_layers": 0,
  "hidden_size": 128,
  "nonlinearity": "tanh",
  "policy_initialization": "xavier_uniform",
  "policy_init_gain": 1.0,
  "actor_critic_share_weights": false,
  "use_spectral_norm": true,
  "adaptive_stddev": false,
  "initial_stddev": 1.0,
  "scenario_name": "4v4/ShootMissile/Selfplay3_altitude_noheading2",
  "num_good_agents": 4,
  "num_adversaries": 4,
  "num_neighbors_obs": 3,
  "num_oppo_obs": 4,
  "num_obstacle_obs": 4,
  "num_landmarks": 4,
  "lambda_t": 1.0,
  "experiment_summaries_interval": 20,
  "adam_eps": 1e-06,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "gae_lambda": 1.0,
  "rollout": 128,
  "num_workers": 1,
  "recurrence": 1,
  "use_rnn": false,
  "rnn_type": "lstm",
  "rnn_num_layers": 1,
  "num_heads": 4,
  "attention_size": 32,
  "num_layer": 2,
  "ppo_clip_ratio": 0.2,
  "ppo_clip_value": 5.0,
  "batch_size": 1024,
  "num_batches_per_iteration": 1,
  "ppo_epochs": 1,
  "num_minibatches_to_accumulate": -1,
  "max_grad_norm": 5.0,
  "exploration_loss_coeff": 0.0,
  "value_loss_coeff": 0.5,
  "kl_loss_coeff": 0.0,
  "exploration_loss": "entropy",
  "num_envs_per_worker": 2,
  "worker_num_splits": 2,
  "num_policies": 1,
  "policy_workers_per_policy": 1,
  "max_policy_lag": 100000000,
  "traj_buffers_excess_ratio": 1.3,
  "decorrelate_experience_max_seconds": 10,
  "decorrelate_envs_on_one_worker": true,
  "with_vtrace": false,
  "vtrace_rho": 1.0,
  "vtrace_c": 1.0,
  "set_workers_cpu_affinity": true,
  "force_envs_single_thread": true,
  "reset_timeout_seconds": 120,
  "default_niceness": 0,
  "train_in_background_thread": true,
  "learner_main_loop_num_cores": 1,
  "actor_worker_gpus": [],
  "with_pbt": false,
  "pbt_mix_policies_in_one_env": true,
  "pbt_period_env_steps": 5000000,
  "pbt_start_mutation": 20000000,
  "pbt_replace_fraction": 0.3,
  "pbt_mutation_rate": 0.15,
  "pbt_replace_reward_gap": 0.1,
  "pbt_replace_reward_gap_absolute": 1e-06,
  "pbt_optimize_batch_size": false,
  "pbt_optimize_gamma": false,
  "pbt_target_objective": "true_reward",
  "pbt_perturb_min": 1.05,
  "pbt_perturb_max": 1.5,
  "use_cpc": false,
  "cpc_forward_steps": 8,
  "cpc_time_subsample": 6,
  "cpc_forward_subsample": 2,
  "with_wandb": false,
  "wandb_user": null,
  "wandb_project": "sample_factory",
  "wandb_group": null,
  "wandb_job_type": "SF",
  "wandb_tags": [],
  "lr2": 0.0001,
  "eps2": 0.0001,
  "clip_grad_norm": 5,
  "state_dim": 16,
  "rnn_hidden_dim": 32,
  "free_nats": 3,
  "collect_interval": 100,
  "batch_size2": 8,
  "chunk_length": 16,
  "horizon": 3,
  "N_iterations": 4,
  "N_candidates": 1000,
  "N_top_candidates": 100,
  "oppo_model_ally": true,
  "intention_model": true,
  "local_time_attention": false,
  "global_space_attention": false,
  "global_time_attention": true,
  "pop_size": 128,
  "elitism": false,
  "n_grad": 5,
  "cov_init": 0.001,
  "cov_limit": 1e-05,
  "cov_alpha": 0.01,
  "mut_mag": 0.05,
  "mult_noise": false,
  "alpha_e": 2.0,
  "epsilon_decay": 0.995,
  "prob": 1.0,
  "decay": 0.997,
  "benchmark": false,
  "sampler_only": false,
  "env_frameskip": 1,
  "env_framestack": 4,
  "pixel_format": "CHW",
  "quads_discretize_actions": -1,
  "quads_clip_input": false,
  "quads_effort_reward": null,
  "quads_episode_duration": 15.0,
  "quads_num_agents": 8,
  "quads_neighbor_hidden_size": 128,
  "quads_neighbor_encoder_type": "attention",
  "quads_collision_reward": 5.0,
  "quads_collision_obstacle_reward": 5.0,
  "quads_settle_reward": 0.0,
  "quads_settle": false,
  "quads_vel_reward_out_range": 0.8,
  "quads_settle_range_meters": 1.0,
  "quads_collision_hitbox_radius": 2.0,
  "quads_collision_falloff_radius": 4.0,
  "quads_collision_smooth_max_penalty": 10.0,
  "neighbor_obs_type": "pos_vel",
  "quads_use_numba": false,
  "quads_obstacle_mode": "no_obstacles",
  "quads_obstacle_num": 0,
  "quads_obstacle_type": "sphere",
  "quads_obstacle_size": 0.0,
  "quads_obstacle_traj": "gravity",
  "quads_local_obs": 6,
  "quads_local_coeff": 1.0,
  "quads_local_metric": "dist",
  "quads_view_mode": "local",
  "quads_adaptive_env": false,
  "quads_mode": "mix",
  "quads_formation": "circle_horizontal",
  "quads_formation_size": 0.0,
  "room_dims": [
    10,
    10,
    10
  ],
  "quads_obs_repr": "xyz_vxyz_R_omega",
  "replay_buffer_sample_prob": 0.0,
  "anneal_collision_steps": 30000000.0,
  "quads_obstacle_obs_mode": "relative",
  "quads_obstacle_hidden_size": 128,
  "quads_collision_obst_smooth_max_penalty": 10.0,
  "quads_obst_penalty_fall_off": 10.0,
  "command_line": "--env=dogfight_multi --train_for_env_steps=160000000 --algo=APPO --use_rnn=False --rnn_type=lstm --num_heads=4 --attention_size=32 --num_layer=1 --num_workers=18 --num_envs_per_worker=2 --learning_rate=0.0003 --ppo_clip_value=5.0 --recurrence=1 --nonlinearity=tanh --actor_critic_share_weights=False --policy_initialization=xavier_uniform --adaptive_stddev=False --with_vtrace=False --max_policy_lag=100000000 --hidden_size=128 --encoder_custom=quad_multi_encoder --with_pbt=False --quads_neighbor_hidden_size=128 --quads_obstacle_hidden_size=128 --gae_lambda=1.00 --max_grad_norm=5.0 --exploration_loss_coeff=0.0 --rollout=128 --batch_size=1024 --quads_episode_duration=110.0 --quads_collision_reward=5.0 --quads_collision_smooth_max_penalty=10.0 --quads_collision_obstacle_reward=5 --quads_collision_obst_smooth_max_penalty=10 --quads_neighbor_encoder_type=attention --replay_buffer_sample_prob=0.75 --anneal_collision_steps=30000000 --experiment=dogfight4v4_v10 --num_good_agents=4 --num_adversaries=4 --num_landmarks=4 --num_neighbors_obs=3 --num_oppo_obs=4 --num_obstacle_obs=4 --use_spectral_norm=True --quads_num_agents=8 --seed=1 --oppo_model_ally=True --local_time_attention=False --global_time_attention=True --scenario_name=4v4/ShootMissile/Selfplay3_altitude_noheading2 --intention_model=True",
  "cli_args": {
    "algo": "APPO",
    "env": "dogfight_multi",
    "experiment": "dogfight4v4_v10",
    "seed": 1,
    "learning_rate": 0.0003,
    "train_for_env_steps": 160000000,
    "encoder_custom": "quad_multi_encoder",
    "hidden_size": 128,
    "nonlinearity": "tanh",
    "policy_initialization": "xavier_uniform",
    "actor_critic_share_weights": false,
    "use_spectral_norm": true,
    "adaptive_stddev": false,
    "scenario_name": "4v4/ShootMissile/Selfplay3_altitude_noheading2",
    "num_good_agents": 4,
    "num_adversaries": 4,
    "num_neighbors_obs": 3,
    "num_oppo_obs": 4,
    "num_obstacle_obs": 4,
    "num_landmarks": 4,
    "gae_lambda": 1.0,
    "rollout": 128,
    "num_workers": 18,
    "recurrence": 1,
    "use_rnn": false,
    "rnn_type": "lstm",
    "num_heads": 4,
    "attention_size": 32,
    "num_layer": 2,
    "ppo_clip_value": 5.0,
    "batch_size": 1024,
    "max_grad_norm": 5.0,
    "exploration_loss_coeff": 0.0,
    "num_envs_per_worker": 2,
    "max_policy_lag": 100000000,
    "with_vtrace": false,
    "with_pbt": false,
    "oppo_model_ally": true,
    "intention_model": true,
    "local_time_attention": false,
    "global_time_attention": true,
    "quads_episode_duration": 110.0,
    "quads_num_agents": 8,
    "quads_neighbor_hidden_size": 128,
    "quads_neighbor_encoder_type": "attention",
    "quads_collision_reward": 5.0,
    "quads_collision_obstacle_reward": 5.0,
    "quads_collision_smooth_max_penalty": 10.0,
    "replay_buffer_sample_prob": 0.75,
    "anneal_collision_steps": 30000000.0,
    "quads_obstacle_hidden_size": 128,
    "quads_collision_obst_smooth_max_penalty": 10.0
  },
  "git_hash": "unknown",
  "git_repo_name": "not a git repository"
}
